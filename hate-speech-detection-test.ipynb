{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7257995,"sourceType":"datasetVersion","datasetId":4205998}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"import subprocess\nimport threading\n\n#istallazione di ollama\n!curl -fsSL https://ollama.com/install.sh | sh# This Python 3 environment comes with many helpful analytics libraries installed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-09T08:47:26.586287Z","iopub.execute_input":"2024-08-09T08:47:26.586701Z","iopub.status.idle":"2024-08-09T08:47:27.717215Z","shell.execute_reply.started":"2024-08-09T08:47:26.586667Z","shell.execute_reply":"2024-08-09T08:47:27.716203Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/bin/bash: sh#: command not found\ncurl: (23) Failure writing output to destination, passed 1378 returned 1349\n","output_type":"stream"}]},{"cell_type":"code","source":"def start_ollama():\n    t = threading.Thread(target=lambda: subprocess.run([\"ollama\", \"serve\"]),daemon=True)\n    t.start()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:27.720524Z","iopub.execute_input":"2024-08-09T08:47:27.720847Z","iopub.status.idle":"2024-08-09T08:47:27.726003Z","shell.execute_reply.started":"2024-08-09T08:47:27.720819Z","shell.execute_reply":"2024-08-09T08:47:27.725059Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def pull_model(local_llm):\n    !ollama pull local_llm","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:27.727157Z","iopub.execute_input":"2024-08-09T08:47:27.727497Z","iopub.status.idle":"2024-08-09T08:47:27.737210Z","shell.execute_reply.started":"2024-08-09T08:47:27.727466Z","shell.execute_reply":"2024-08-09T08:47:27.736422Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def start_model(local_llm):        \n    t2 = threading.Thread(target=lambda: subprocess.run([\"ollama\", \"run\", local_llm]),daemon=True)\n    t2.start()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:27.738832Z","iopub.execute_input":"2024-08-09T08:47:27.739122Z","iopub.status.idle":"2024-08-09T08:47:27.747405Z","shell.execute_reply.started":"2024-08-09T08:47:27.739092Z","shell.execute_reply":"2024-08-09T08:47:27.746573Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%%capture --no-stderr\n%pip install -U scikit-learn==1.3 langchain-ai21 langchain_community tiktoken langchainhub langchain langgraph","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:27.748512Z","iopub.execute_input":"2024-08-09T08:47:27.748772Z","iopub.status.idle":"2024-08-09T08:47:40.918008Z","shell.execute_reply.started":"2024-08-09T08:47:27.748750Z","shell.execute_reply":"2024-08-09T08:47:40.916902Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:40.920357Z","iopub.execute_input":"2024-08-09T08:47:40.920679Z","iopub.status.idle":"2024-08-09T08:47:40.926024Z","shell.execute_reply.started":"2024-08-09T08:47:40.920652Z","shell.execute_reply":"2024-08-09T08:47:40.925143Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:40.927079Z","iopub.execute_input":"2024-08-09T08:47:40.927401Z","iopub.status.idle":"2024-08-09T08:47:40.937770Z","shell.execute_reply.started":"2024-08-09T08:47:40.927370Z","shell.execute_reply":"2024-08-09T08:47:40.936955Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Dati","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/datasets/waalbannyantudre/hate-speech-detection-curated-dataset","metadata":{}},{"cell_type":"markdown","source":"https://www.sciencedirect.com/science/article/pii/S2352340922010356","metadata":{}},{"cell_type":"code","source":"# todo #all'incirca 7.000 testi di test\n\ndf = pd.read_csv(\"/kaggle/input/hate-speech-detection-curated-dataset/HateSpeechDatasetBalanced.csv\")\n\nprint(len(df))\n\n#label_0 = df[df[\"Label\"]==0] #no hate speech\n#label_1 = df[df[\"Label\"]==1] #hate speech\n#print(f\"Label con valore 0: {len(label_0)}\")\n#print(f\"Label con valore 1: {len(label_1)}\")\n\n# Campiona l'1% del DataFrame\nsampled_df = df.sample(frac=0.01, random_state=42)\n\nx_test = sampled_df[\"Content\"]\ny_test = sampled_df[\"Label\"]\n\nprint(len(x_test))\nprint(len(y_test))\n\nlabel_0 = sampled_df[sampled_df[\"Label\"]==0] #no hate speech\nlabel_1 = sampled_df[sampled_df[\"Label\"]==1] #hate speech\nprint(f\"Label con valore 0: {len(label_0)}\")\nprint(f\"Label con valore 1: {len(label_1)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:40.938888Z","iopub.execute_input":"2024-08-09T08:47:40.939218Z","iopub.status.idle":"2024-08-09T08:47:42.838770Z","shell.execute_reply.started":"2024-08-09T08:47:40.939188Z","shell.execute_reply":"2024-08-09T08:47:42.837861Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"726119\n7261\n7261\nLabel con valore 0: 3584\nLabel con valore 1: 3677\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hate speech","metadata":{}},{"cell_type":"code","source":"model = \"llama3.1\"\n\nstart_ollama()\npull_model(model)\nstart_model(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:42.839983Z","iopub.execute_input":"2024-08-09T08:47:42.840259Z","iopub.status.idle":"2024-08-09T08:47:43.844131Z","shell.execute_reply.started":"2024-08-09T08:47:42.840236Z","shell.execute_reply":"2024-08-09T08:47:43.842302Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Exception in thread Thread-8 (<lambda>):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/tmp/ipykernel_34/2396888887.py\", line 2, in <lambda>\n  File \"/opt/conda/lib/python3.10/subprocess.py\", line 503, in run\n    with Popen(*popenargs, **kwargs) as process:\n  File \"/opt/conda/lib/python3.10/subprocess.py\", line 971, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/opt/conda/lib/python3.10/subprocess.py\", line 1863, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'ollama'\n","output_type":"stream"},{"name":"stdout","text":"/bin/bash: ollama: command not found\n","output_type":"stream"},{"name":"stderr","text":"Exception in thread Thread-9 (<lambda>):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/tmp/ipykernel_34/1267679444.py\", line 2, in <lambda>\n  File \"/opt/conda/lib/python3.10/subprocess.py\", line 503, in run\n    with Popen(*popenargs, **kwargs) as process:\n  File \"/opt/conda/lib/python3.10/subprocess.py\", line 971, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"/opt/conda/lib/python3.10/subprocess.py\", line 1863, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'ollama'\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = PromptTemplate(\n        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an helpful assistant who has to detect the presence of hate speech.\n            Hate speech is speech that attacks a person or group based on attributes such as race, religion, ethnic origin, national origin, sex, disability, sexual orientation, or gender identity. \n            You have to answer \"yes\" if it contains hate speech, or \"no\" if it doesn't contain hate speech. NO PREAMBLE, NO EXPLANATIONS.\n            <|eot_id|><|start_header_id|>user<|end_header_id|> \n            Do you think this document contain hate speech? document: {document}.\n            <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n        input_variables=[\"document\"],\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hate_speech_detection(prompt, model):\n    llm = ChatOllama(model=model, temperature=0)\n    hate_speech_detection = prompt | llm | StrOutputParser()\n    return hate_speech_detection","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label 0: no-hate speech (no answer)\n# Label 1: hate speech (yes answer)\n\ndef predict(prompt,model,x_test):\n    y_pred = []\n    for x in tqdm(x_test):\n        answer = hate_speech_detection(prompt,model).invoke({\"document\":x})\n        if answer.lower() == \"yes\": y_pred.append(1)\n        elif answer.lower() == \"no\": y_pred.append(0)\n    return y_pred\n\ny_pred = predict(prompt,model,x_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Valutazione del modello\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred, labels=[0,1], output_dict=True)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")\nprint(f\"Classification Report:\\n{class_report}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salva risultati\n\nimport json\n\ndef load_json(filename):\n    with open(filename, 'r') as file:\n        return json.load(file)\n\ndef write_file(filename,content):\n    with open(filename, 'w') as file:\n        json.dump(content, file, indent=4)\n    \nwrite_file(\"/kaggle/working/test_hate_speech\", class_report)","metadata":{},"execution_count":null,"outputs":[]}]}