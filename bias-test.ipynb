{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7453039,"sourceType":"datasetVersion","datasetId":1124292}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6e00ec08f40e41a2b6f68f9acbc64ed8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ea4d6adf6bf4698a8ce40c717735968","IPY_MODEL_5b0cf45b5555475c9481f830ed0a714c","IPY_MODEL_fabc2ab3a92e431ca4b36d100eae575b"],"layout":"IPY_MODEL_05835461036f4a6294f9634bcc3df472"}},"5ea4d6adf6bf4698a8ce40c717735968":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4dd1bcc2d044d179b447b57b45419cc","placeholder":"​","style":"IPY_MODEL_5fc4fae7bb0d4f0f807359bfd51b6d03","value":"tokenizer_config.json: 100%"}},"5b0cf45b5555475c9481f830ed0a714c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_875435f92db84710adcf07c480fa8293","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec1b21bb1db8477e928e965fe9b3aa0c","value":2}},"fabc2ab3a92e431ca4b36d100eae575b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8fa66cb2ed544acab5eb2eef9b71d45","placeholder":"​","style":"IPY_MODEL_3407e5bba06247b7903390d4ed99b072","value":" 2.00/2.00 [00:00&lt;00:00, 34.7B/s]"}},"05835461036f4a6294f9634bcc3df472":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4dd1bcc2d044d179b447b57b45419cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc4fae7bb0d4f0f807359bfd51b6d03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"875435f92db84710adcf07c480fa8293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1b21bb1db8477e928e965fe9b3aa0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8fa66cb2ed544acab5eb2eef9b71d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3407e5bba06247b7903390d4ed99b072":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ad37e101243470cab5278a4b9b1f745":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48e0b27b1811427a9b17ddc0fdccebe1","IPY_MODEL_f9a005045ca84161858c9a24a7c53906","IPY_MODEL_810262c9b98c48de9c8397fde7319bee"],"layout":"IPY_MODEL_66521c3c904e4e95b118365209ef24b1"}},"48e0b27b1811427a9b17ddc0fdccebe1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6904592bb8746ce8f4c99313922d319","placeholder":"​","style":"IPY_MODEL_9cf07bfc7a894e5ea18197cd7adf749c","value":"config.json: 100%"}},"f9a005045ca84161858c9a24a7c53906":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a7f283f46d749debb57d8d0b37b18c9","max":657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0253bc661114736adb2d94b70c9c296","value":657}},"810262c9b98c48de9c8397fde7319bee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4fb30f394af4547b6f043fd550af0f6","placeholder":"​","style":"IPY_MODEL_cf44dfa4ab1949bebadd7fc1ccf61cb0","value":" 657/657 [00:00&lt;00:00, 12.5kB/s]"}},"66521c3c904e4e95b118365209ef24b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6904592bb8746ce8f4c99313922d319":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cf07bfc7a894e5ea18197cd7adf749c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a7f283f46d749debb57d8d0b37b18c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0253bc661114736adb2d94b70c9c296":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4fb30f394af4547b6f043fd550af0f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf44dfa4ab1949bebadd7fc1ccf61cb0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b4db9be239045fc90f3c4a49ed2f172":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6192f5375f404044b859f8e28cdb70bb","IPY_MODEL_9fadff35335d4d608e89c7254de49a89","IPY_MODEL_72c8c7bd444b44a79f9282ab95bff7d4"],"layout":"IPY_MODEL_4d084e9a66e342f5b1bf67971ab3c7f8"}},"6192f5375f404044b859f8e28cdb70bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0d113cedc57441fa0e8fae1d8a79240","placeholder":"​","style":"IPY_MODEL_cdbae641d3a745a385937b9c92689ee4","value":"vocab.txt: 100%"}},"9fadff35335d4d608e89c7254de49a89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c27cce227bb467da5aa4a7e2d73fbb3","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4e8eb15525148b6bba89c449031e685","value":231508}},"72c8c7bd444b44a79f9282ab95bff7d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6059639987b24dc791086d42c0924ad1","placeholder":"​","style":"IPY_MODEL_7546347f7d2e4220b99304b2585a87e9","value":" 232k/232k [00:00&lt;00:00, 334kB/s]"}},"4d084e9a66e342f5b1bf67971ab3c7f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0d113cedc57441fa0e8fae1d8a79240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdbae641d3a745a385937b9c92689ee4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c27cce227bb467da5aa4a7e2d73fbb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4e8eb15525148b6bba89c449031e685":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6059639987b24dc791086d42c0924ad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7546347f7d2e4220b99304b2585a87e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7019efdd9aa74a6a9fa67cc4fa820d39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_273b790fc5eb47f2bdd4e2aa25374b2f","IPY_MODEL_d042eb8247594bbbbc514ee16dfd39a1","IPY_MODEL_bdc1b2c595f54a979a189d6bb50b0b7c"],"layout":"IPY_MODEL_e182cb8fdb604f18b7282d10fdcad782"}},"273b790fc5eb47f2bdd4e2aa25374b2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f79d0f6e8f5643cba899032ea11a1f36","placeholder":"​","style":"IPY_MODEL_3bcdcca0e72c4ac08338e5713bba04eb","value":"special_tokens_map.json: 100%"}},"d042eb8247594bbbbc514ee16dfd39a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38d2b98f482a491db3ea878ec60010ae","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_97818ddc45754c5d94166defd57628dd","value":112}},"bdc1b2c595f54a979a189d6bb50b0b7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64affacae4ae4df78abdfacad78c0d08","placeholder":"​","style":"IPY_MODEL_f0c6c027d2cb4ad58117c7a9ceb382ba","value":" 112/112 [00:00&lt;00:00, 2.25kB/s]"}},"e182cb8fdb604f18b7282d10fdcad782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f79d0f6e8f5643cba899032ea11a1f36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bcdcca0e72c4ac08338e5713bba04eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38d2b98f482a491db3ea878ec60010ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97818ddc45754c5d94166defd57628dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64affacae4ae4df78abdfacad78c0d08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0c6c027d2cb4ad58117c7a9ceb382ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ef1dfb6306442e48770014a0ea0ed60":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12ef011323594e0ca88671c59592cb55","IPY_MODEL_d69d6e06c6c241aba391f324b7f9c9d1","IPY_MODEL_1cf416c088df4503a0a532fa33cdc001"],"layout":"IPY_MODEL_f8357265eb134dfea4489545cf23f1e5"}},"12ef011323594e0ca88671c59592cb55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdf61d184a2540cfb03fa015686353fa","placeholder":"​","style":"IPY_MODEL_48891582379949c4ad43cfd64225ff40","value":"tf_model.h5: 100%"}},"d69d6e06c6c241aba391f324b7f9c9d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2f4ef39c29e4ec9bd4f19f170192138","max":267951896,"min":0,"orientation":"horizontal","style":"IPY_MODEL_194b6e5a3d054b60881015190c5ca45c","value":267951896}},"1cf416c088df4503a0a532fa33cdc001":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_893fe4790c6843c5bd300d29dfbd43a3","placeholder":"​","style":"IPY_MODEL_ab68005959e841bbb496ad70e679acaf","value":" 268M/268M [00:05&lt;00:00, 62.7MB/s]"}},"f8357265eb134dfea4489545cf23f1e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdf61d184a2540cfb03fa015686353fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48891582379949c4ad43cfd64225ff40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2f4ef39c29e4ec9bd4f19f170192138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"194b6e5a3d054b60881015190c5ca45c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"893fe4790c6843c5bd300d29dfbd43a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab68005959e841bbb496ad70e679acaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{"id":"604zKLdT0g7v"}},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHFl0_Uf0x5O","outputId":"4f3ed006-0901-41bc-cb12-c4980de445fa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\nimport threading\n\n#istallazione di ollama\n!curl -fsSL https://ollama.com/install.sh | sh","metadata":{"id":"QHiEhq860g7w","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d787edc6-faa0-4049-e118-206722a36795","execution":{"iopub.status.busy":"2024-08-13T16:56:06.912721Z","iopub.execute_input":"2024-08-13T16:56:06.913018Z","iopub.status.idle":"2024-08-13T16:56:11.010849Z","shell.execute_reply.started":"2024-08-13T16:56:06.912992Z","shell.execute_reply":"2024-08-13T16:56:11.009917Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":">>> Downloading ollama...\n######################################################################## 100.0%#=#=#                                                                          ###################                                 57.8%\n>>> Installing ollama to /usr/local/bin...\n>>> Creating ollama user...\n>>> Adding ollama user to video group...\n>>> Adding current user to ollama group...\n>>> Creating ollama systemd service...\n>>> NVIDIA GPU installed.\n>>> The Ollama API is now available at 127.0.0.1:11434.\n>>> Install complete. Run \"ollama\" from the command line.\n","output_type":"stream"}]},{"cell_type":"code","source":"def start_ollama():\n    t = threading.Thread(target=lambda: subprocess.run([\"ollama\", \"serve\"]),daemon=True)\n    t.start()","metadata":{"id":"Gy49DnUo0g7x","execution":{"iopub.status.busy":"2024-08-13T16:56:42.155979Z","iopub.execute_input":"2024-08-13T16:56:42.156351Z","iopub.status.idle":"2024-08-13T16:56:42.162047Z","shell.execute_reply.started":"2024-08-13T16:56:42.156321Z","shell.execute_reply":"2024-08-13T16:56:42.160703Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def pull_model(local_llm):\n    !ollama pull local_llm","metadata":{"id":"MkiD3bfX0g7y","execution":{"iopub.status.busy":"2024-08-13T16:56:42.421677Z","iopub.execute_input":"2024-08-13T16:56:42.422413Z","iopub.status.idle":"2024-08-13T16:56:42.426746Z","shell.execute_reply.started":"2024-08-13T16:56:42.422382Z","shell.execute_reply":"2024-08-13T16:56:42.425872Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def start_model(local_llm):\n    t2 = threading.Thread(target=lambda: subprocess.run([\"ollama\", \"run\", local_llm]),daemon=True)\n    t2.start()","metadata":{"id":"4ivHLOZg0g7y","execution":{"iopub.status.busy":"2024-08-13T16:56:44.853751Z","iopub.execute_input":"2024-08-13T16:56:44.854079Z","iopub.status.idle":"2024-08-13T16:56:44.859210Z","shell.execute_reply.started":"2024-08-13T16:56:44.854055Z","shell.execute_reply":"2024-08-13T16:56:44.858275Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"%%capture --no-stderr\n%pip install -U rouge-score nltk bert-score scikit-learn==1.3 langchain-ai21 langchain_community tiktoken langchainhub langchain langgraph","metadata":{"id":"_lxYyOPR0g7y","execution":{"iopub.status.busy":"2024-08-13T16:56:47.974810Z","iopub.execute_input":"2024-08-13T16:56:47.975599Z","iopub.status.idle":"2024-08-13T16:57:20.802724Z","shell.execute_reply.started":"2024-08-13T16:56:47.975567Z","shell.execute_reply":"2024-08-13T16:57:20.801524Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n#os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"","metadata":{"id":"hdGp18Gl0g7y","execution":{"iopub.status.busy":"2024-08-13T16:57:20.804545Z","iopub.execute_input":"2024-08-13T16:57:20.804853Z","iopub.status.idle":"2024-08-13T16:57:20.809515Z","shell.execute_reply.started":"2024-08-13T16:57:20.804814Z","shell.execute_reply":"2024-08-13T16:57:20.808650Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom tqdm import tqdm\nfrom langchain_community.llms import Ollama\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import PromptTemplate","metadata":{"id":"TvGpl-Sh0g7y","execution":{"iopub.status.busy":"2024-08-13T16:57:20.810622Z","iopub.execute_input":"2024-08-13T16:57:20.810897Z","iopub.status.idle":"2024-08-13T16:57:22.535662Z","shell.execute_reply.started":"2024-08-13T16:57:20.810870Z","shell.execute_reply":"2024-08-13T16:57:22.534709Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import pipeline\nimport torch\n\ndevice = 0 if torch.cuda.is_available() else -1\n\n# response: biased or non-biased\nbias_model_tokenizer = AutoTokenizer.from_pretrained(\"d4data/bias-detection-model\")\nbias_model = AutoModelForSequenceClassification.from_pretrained(\"d4data/bias-detection-model\",from_tf=True)","metadata":{"id":"LPqRGmvs0g7z","colab":{"base_uri":"https://localhost:8080/","height":378,"referenced_widgets":["6e00ec08f40e41a2b6f68f9acbc64ed8","5ea4d6adf6bf4698a8ce40c717735968","5b0cf45b5555475c9481f830ed0a714c","fabc2ab3a92e431ca4b36d100eae575b","05835461036f4a6294f9634bcc3df472","a4dd1bcc2d044d179b447b57b45419cc","5fc4fae7bb0d4f0f807359bfd51b6d03","875435f92db84710adcf07c480fa8293","ec1b21bb1db8477e928e965fe9b3aa0c","e8fa66cb2ed544acab5eb2eef9b71d45","3407e5bba06247b7903390d4ed99b072","0ad37e101243470cab5278a4b9b1f745","48e0b27b1811427a9b17ddc0fdccebe1","f9a005045ca84161858c9a24a7c53906","810262c9b98c48de9c8397fde7319bee","66521c3c904e4e95b118365209ef24b1","d6904592bb8746ce8f4c99313922d319","9cf07bfc7a894e5ea18197cd7adf749c","7a7f283f46d749debb57d8d0b37b18c9","b0253bc661114736adb2d94b70c9c296","d4fb30f394af4547b6f043fd550af0f6","cf44dfa4ab1949bebadd7fc1ccf61cb0","0b4db9be239045fc90f3c4a49ed2f172","6192f5375f404044b859f8e28cdb70bb","9fadff35335d4d608e89c7254de49a89","72c8c7bd444b44a79f9282ab95bff7d4","4d084e9a66e342f5b1bf67971ab3c7f8","f0d113cedc57441fa0e8fae1d8a79240","cdbae641d3a745a385937b9c92689ee4","5c27cce227bb467da5aa4a7e2d73fbb3","f4e8eb15525148b6bba89c449031e685","6059639987b24dc791086d42c0924ad1","7546347f7d2e4220b99304b2585a87e9","7019efdd9aa74a6a9fa67cc4fa820d39","273b790fc5eb47f2bdd4e2aa25374b2f","d042eb8247594bbbbc514ee16dfd39a1","bdc1b2c595f54a979a189d6bb50b0b7c","e182cb8fdb604f18b7282d10fdcad782","f79d0f6e8f5643cba899032ea11a1f36","3bcdcca0e72c4ac08338e5713bba04eb","38d2b98f482a491db3ea878ec60010ae","97818ddc45754c5d94166defd57628dd","64affacae4ae4df78abdfacad78c0d08","f0c6c027d2cb4ad58117c7a9ceb382ba","9ef1dfb6306442e48770014a0ea0ed60","12ef011323594e0ca88671c59592cb55","d69d6e06c6c241aba391f324b7f9c9d1","1cf416c088df4503a0a532fa33cdc001","f8357265eb134dfea4489545cf23f1e5","bdf61d184a2540cfb03fa015686353fa","48891582379949c4ad43cfd64225ff40","a2f4ef39c29e4ec9bd4f19f170192138","194b6e5a3d054b60881015190c5ca45c","893fe4790c6843c5bd300d29dfbd43a3","ab68005959e841bbb496ad70e679acaf"]},"outputId":"803b5922-3680-4caf-958f-c58e14507e19","execution":{"iopub.status.busy":"2024-08-13T16:09:38.218158Z","iopub.execute_input":"2024-08-13T16:09:38.218863Z","iopub.status.idle":"2024-08-13T16:10:06.105625Z","shell.execute_reply.started":"2024-08-13T16:09:38.218816Z","shell.execute_reply":"2024-08-13T16:10:06.104308Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-08-13 16:09:46.026689: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-13 16:09:46.026902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-13 16:09:46.199202: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7420bc96267143a5a35e727f1b0235eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/657 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7a6dc66522c4d0a9418e427e5e95598"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49f6a715d7aa491199e79038eb9a0488"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a77c6c19c16b4e5089c43f368d461f21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7aa5518ef57447cb4a1875151bbfcc9"}},"metadata":{}},{"name":"stderr","text":"All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n\nAll the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Bias detection","metadata":{"id":"qZiAxruv0g7z"}},{"cell_type":"markdown","source":"## Dati","metadata":{"id":"plzWEOlm0g7z"}},{"cell_type":"markdown","source":"https://www.kaggle.com/datasets/timospinde/mbic-a-media-bias-annotation-dataset (vedi anche paper di riferimento MBIC)","metadata":{"id":"mZTXY5EA0g7z"}},{"cell_type":"code","source":"df = pd.read_excel(\"/kaggle/input/mbic-a-media-bias-annotation-dataset/labeled_dataset.xlsx\")\n#/kaggle/input/mbic-a-media-bias-annotation-dataset/labeled_dataset.xlsx\n#/content/drive/MyDrive/predictions/labeled_dataset.xlsx\n\nprint(len(df))\n\nprint(df[\"Label_bias\"].unique()) #ci sono tre valori, i no-agreement come li gestiamo?\n# eliminiamo i no-agreement (non c'è accordo che siano biased o non-biased).\n\ndf = df[df[\"Label_bias\"] != \"No agreement\"]\n\ndf_biased = df[df[\"Label_bias\"] == \"Biased\"]\n\nprint(len(df))\nprint(len(df_biased)) #1000 tesi biased","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQyCrQdS4qPF","outputId":"1185b6c6-8b70-477e-ecb9-bd0c9e99df21","execution":{"iopub.status.busy":"2024-08-13T16:57:22.537535Z","iopub.execute_input":"2024-08-13T16:57:22.537963Z","iopub.status.idle":"2024-08-13T16:57:23.837807Z","shell.execute_reply.started":"2024-08-13T16:57:22.537938Z","shell.execute_reply":"2024-08-13T16:57:23.836810Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"1700\n['Biased' 'Non-biased' 'No agreement']\n1551\n1018\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n  warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"#all'incirca 1551 testi di test, news biased e non biased\n\n# Biased = 0\n# Non-biased = 1\n\nx_test = df[\"sentence\"]\ny_test_pre = df[\"Label_bias\"] #Biased #Non-biased\n\nprint(len(x_test))\nprint(len(y_test_pre))\n\nlabel_biased = df[df[\"Label_bias\"]==\"Biased\"] #Label 0\nlabel_non_biased = df[df[\"Label_bias\"]==\"Non-biased\"] #Label 1\nprint(f\"Label con valore Biased: {len(label_biased)}\")\nprint(f\"Label con valore Non-biased: {len(label_non_biased)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYzGitz339ql","outputId":"a08f733f-decc-4af7-ef5b-b6e004dce690","execution":{"iopub.status.busy":"2024-08-13T16:57:23.839134Z","iopub.execute_input":"2024-08-13T16:57:23.839561Z","iopub.status.idle":"2024-08-13T16:57:23.848612Z","shell.execute_reply.started":"2024-08-13T16:57:23.839532Z","shell.execute_reply":"2024-08-13T16:57:23.847394Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"1551\n1551\nLabel con valore Biased: 1018\nLabel con valore Non-biased: 533\n","output_type":"stream"}]},{"cell_type":"code","source":"y_test = [0 if label==\"Biased\" else 1 for label in y_test_pre]\n\nprint(f\"Label con valore Biased: {y_test.count(0)}\")\nprint(f\"Label con valore Non-biased: {y_test.count(1)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D--SFN5k7iAf","outputId":"4f17db4c-8137-4b80-a9c5-68d720bdefa7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{"id":"2lBfx_nC0g70"}},{"cell_type":"code","source":"examples = [\n    {\"input\": \"I'm not racist, but [group] are just not as smart as us.\", \"output\": \"biased\"},\n    {\"input\": \"Women should know their place.\", \"output\": \"biased\"},\n    {\"input\": \"She excelled in her exams due to her dedication and hard work.\", \"output\": \"no-biased\"},\n    {\"input\": \"People from that country are lazy and unproductive.\", \"output\": \"biased\"},\n    {\"input\": \"He was selected for the role based on his qualifications and experience.\", \"output\": \"non-biased\"},\n    {\"input\": \"Students from that school always perform poorly.\", \"output\": \"biased\"},\n    {\"input\": \"The decision was made after a thorough review of all the candidates.\", \"output\": \"no-biased\"},\n    {\"input\": \"He's not suitable for the job because he's too old.\", \"output\": \"biased\"},\n]","metadata":{"id":"EbfdUBvR0g70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n\ndef create_prompt(shot):\n    example_prompt  = ChatPromptTemplate.from_messages(\n        [\n            (\"user\", \"{input}\"),\n            (\"assistant\", \"{output}\"),\n        ]\n    )\n\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\n        example_prompt=example_prompt ,\n        examples=examples[:shot], #:2 two-shot, #4: four-shot #8 eight-shot\n    )\n\n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", \"\"\"You will be provided with a text, and your task is to classify it into\n                        one of two categories: \"biased\" or \"non-biased.\" A text is considered \"biased\"\n                        if it expresses a personal opinion, uses emotional or partial language, or promotes\n                        a particular perspective at the expense of others. A text is considered \"non-biased\"\n                        if it presents facts in a neutral and objective manner, without evident influences.\n                        Give ONLY the class \"biased\" or \"non-biased\", NO PREAMBLE, NO EXPLANATIONS.\"\"\"),\n             few_shot_prompt,\n            (\"user\", \"{input}\"),\n        ] if shot>0 else\n        [\n            (\"system\", \"\"\"You will be provided with a text, and your task is to classify it into\n                        one of two categories: \"biased\" or \"non-biased.\" A text is considered \"biased\"\n                        if it expresses a personal opinion, uses emotional or partial language, or promotes\n                        a particular perspective at the expense of others. A text is considered \"non-biased\"\n                        if it presents facts in a neutral and objective manner, without evident influences.\n                        Give ONLY the class \"biased\" or \"non-biased\", NO PREAMBLE, NO EXPLANATIONS.\"\"\"),\n            (\"user\", \"{input}\"),\n        ]\n    )\n    return prompt","metadata":{"id":"-3XSX81x0g70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# response: biased or non-biased\n\ndef bias_det(llm, shot):\n    prompt_final = create_prompt(shot)\n    bias_det_chain = prompt_final | llm\n    return bias_det_chain","metadata":{"id":"Qg0CWxR_0g70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Conferma label\n# Label 0: biased\n# Label 1: non-biased\n\ndef predict(llm,x_test,shot,encoder):\n    y_pred = []\n    y_pred_label = []\n    if encoder:\n        bias_detection = pipeline('text-classification', model=bias_model, tokenizer=bias_model_tokenizer, device=device) # cuda = 0,1 based on gpu availability\n    else:\n        chain = bias_det(llm,shot)\n    for x in tqdm(x_test):\n        if encoder:\n            answer = bias_detection(x)[0][\"label\"]\n        else:\n            answer = chain.invoke({\"input\": x})\n        if \"non-biased\" in answer.lower(): y_pred.append(1)\n        else: y_pred.append(0)\n        y_pred_label.append(answer) #per verificare che le risposte siano sensate\n    return y_pred, y_pred_label\n\n# True se vogliamo il modello encoder, False se vogliamo usare LLM\n#encoder = True\n#y_pred = predict(prompt,model,x_test,encoder)","metadata":{"id":"ip4ErOVr0g71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport json\n\nmodels = [\"llama3.1\",\"gemma2\",\"mistral\"]\nshots = [0,2,4,8]\n\n\ndef write_file(filename,content):\n    with open(filename, 'w') as file:\n        json.dump(content, file, indent=4)\n\nfor model in models:\n    if model == \"encoder\":\n        y_pred, y_pred_label = predict(None,x_test,0,True)\n        write_file(f\"/content/drive/MyDrive/predictions/prediction_bias_encoder.json\", y_pred)\n    else:\n        start_ollama()\n        pull_model(model)\n        start_model(model)\n        time.sleep(500)\n        llm = Ollama(model=model, temperature=0)\n        for shot in shots:\n            y_pred, y_pred_label = predict(llm,x_test,shot,False)\n            if model==\"llama3.1\":\n                write_file(f\"/content/drive/MyDrive/predictions/prediction_bias_llama31_{shot}_shot.json\", y_pred)\n                write_file(f\"/content/drive/MyDrive/predictions/prediction_label_bias_llama31_{shot}_shot.json\", y_pred_label)\n            else:\n                write_file(f\"/content/drive/MyDrive/predictions/prediction_bias_{model}_{shot}_shot.json\", y_pred)\n                write_file(f\"/content/drive/MyDrive/predictions/prediction_label_bias_{model}_{shot}_shot.json\", y_pred_label)","metadata":{"id":"sr8hm2Qg0g71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Valutazione del modello\n#Label 0: biased\n#Label 1: non biased\nimport json\n\ndef load_json(filename):\n    with open(filename, 'r') as file:\n        return json.load(file)\n\ny_pred = load_json(\"/content/drive/MyDrive/predictions/prediction_bias_0_shot.json\")\n\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred, labels=[0,1], output_dict=True)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")\nprint(f\"Classification Report:\\n{class_report}\")","metadata":{"id":"WscGhB8f0g71","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ca1555a-83a0-436d-e81d-cb283b27821e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salva risultati\n\nimport json\n\ndef load_json(filename):\n    with open(filename, 'r') as file:\n        return json.load(file)\n\ndef write_file(filename,content):\n    with open(filename, 'w') as file:\n        json.dump(content, file, indent=4)\n\n\n#dict_to_write = {\"class_report\":class_report, \"0_0\":int(conf_matrix[0][0]), \"0_1\":int(conf_matrix[0][1]), \"1_0\":int(conf_matrix[1][0]), \"1_1\":int(conf_matrix[1][1])}\n#write_file(\"/kaggle/working/test_bias_mistral_zero_shot.json\", dict_to_write)\n\n#y_pred = [0,1,0]\n#write_file(\"/content/drive/MyDrive/predictions/prova.json\", y_pred)","metadata":{"id":"06rzdzWa0g71"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Debiasing","metadata":{"id":"ScyMRZ260g71"}},{"cell_type":"code","source":"x_test = df_biased[\"sentence\"]\nprint(len(x_test))","metadata":{"id":"Dp-JaJJb0g71","execution":{"iopub.status.busy":"2024-08-13T16:57:23.850034Z","iopub.execute_input":"2024-08-13T16:57:23.850496Z","iopub.status.idle":"2024-08-13T16:57:23.862719Z","shell.execute_reply.started":"2024-08-13T16:57:23.850462Z","shell.execute_reply":"2024-08-13T16:57:23.861805Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"1018\n","output_type":"stream"}]},{"cell_type":"code","source":"def debiasing_answer(local_llm):\n    prompt = PromptTemplate(\n        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> The user will pass you text cointaining biases.\n        Your role is to give a debiased version of the text. Give ONLY the debiased text, NO PREAMBLE, NO EXPLANATIONS.\n        Remember that we should treat people from different socioeconomic statuses, sexual orientations, religions, races, physical appearances, nationalities,\n        gender identities, disabilities, and ages equally. When we do not have sufficient information, we should choose the unknown option, rather\n        than making assumptions based on our stereotypes. \\n\n         <|eot_id|><|start_header_id|>user<|end_header_id|>\n        {text}\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n        input_variables=[\"text\"],\n    )\n    debiasing = prompt | local_llm | StrOutputParser()\n    return debiasing","metadata":{"id":"N_JzsJfJ0g71","execution":{"iopub.status.busy":"2024-08-13T16:58:05.206666Z","iopub.execute_input":"2024-08-13T16:58:05.207326Z","iopub.status.idle":"2024-08-13T16:58:05.213968Z","shell.execute_reply.started":"2024-08-13T16:58:05.207279Z","shell.execute_reply":"2024-08-13T16:58:05.213028Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def debias(llm,x_test):\n    x_pred = []\n    chain = debiasing_answer(llm)\n    for x in tqdm(x_test):\n        answer = chain.invoke({\"text\": x})\n        x_pred.append(answer) \n    return x_pred","metadata":{"execution":{"iopub.status.busy":"2024-08-13T16:58:28.244872Z","iopub.execute_input":"2024-08-13T16:58:28.245672Z","iopub.status.idle":"2024-08-13T16:58:28.250672Z","shell.execute_reply.started":"2024-08-13T16:58:28.245640Z","shell.execute_reply":"2024-08-13T16:58:28.249739Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import time\nimport json\n\n\nmodels = [\"llama3.1\",\"gemma2\",\"mistral\"]\n#shots = [0,2,4,8]\n\n#/kaggle/working/\n#/content/drive/MyDrive/predictions/\n\n\ndef write_file(filename,content):\n    with open(filename, 'w') as file:\n        json.dump(content, file, indent=4)\n\nfor model in models:\n    start_ollama()\n    pull_model(model)\n    start_model(model)\n    time.sleep(500)\n    llm = Ollama(model=model, temperature=0)\n    x_pred = debias(llm,x_test)  \n    if model==\"llama3.1\":\n        write_file(f\"/kaggle/working/debias_llama31.json\", x_pred)\n    else:\n        write_file(f\"/kaggle/working/debias_{model}.json\", x_pred)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T17:05:35.837400Z","iopub.execute_input":"2024-08-13T17:05:35.837828Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Error: listen tcp 127.0.0.1:11434: bind: address already in use\n","output_type":"stream"},{"name":"stdout","text":"[GIN] 2024/08/13 - 17:05:36 | 200 |      28.351µs |       127.0.0.1 | HEAD     \"/\"\n\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h[GIN] 2024/08/13 - 17:05:37 | 200 |  332.686536ms |       127.0.0.1 | POST     \"/api/pull\"\n\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \u001b[?25h\nError: pull model manifest: file does not exist\n[GIN] 2024/08/13 - 17:05:37 | 200 |      24.272µs |       127.0.0.1 | HEAD     \"/\"\n[GIN] 2024/08/13 - 17:05:37 | 200 |   23.451918ms |       127.0.0.1 | POST     \"/api/show\"\n","output_type":"stream"},{"name":"stderr","text":"\u001b[?25l⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25htime=2024-08-13T17:05:37.539Z level=INFO source=sched.go:710 msg=\"new model will fit in available VRAM in single GPU, loading\" model=/root/.ollama/models/blobs/sha256-8eeb52dfb3bb9aefdf9d1ef24b3bdbcfbe82238798c4b918278320b6fcef18fe gpu=GPU-8716c71e-b51e-fa6a-2c7c-09f507fa9cdc parallel=4 available=15720382464 required=\"6.2 GiB\"\ntime=2024-08-13T17:05:37.540Z level=INFO source=memory.go:309 msg=\"offload to cuda\" layers.requested=-1 layers.model=33 layers.offload=33 layers.split=\"\" memory.available=\"[14.6 GiB]\" memory.required.full=\"6.2 GiB\" memory.required.partial=\"6.2 GiB\" memory.required.kv=\"1.0 GiB\" memory.required.allocations=\"[6.2 GiB]\" memory.weights.total=\"4.7 GiB\" memory.weights.repeating=\"4.3 GiB\" memory.weights.nonrepeating=\"411.0 MiB\" memory.graph.full=\"560.0 MiB\" memory.graph.partial=\"677.5 MiB\"\ntime=2024-08-13T17:05:37.541Z level=INFO source=server.go:393 msg=\"starting llama server\" cmd=\"/tmp/ollama958192415/runners/cuda_v11/ollama_llama_server --model /root/.ollama/models/blobs/sha256-8eeb52dfb3bb9aefdf9d1ef24b3bdbcfbe82238798c4b918278320b6fcef18fe --ctx-size 8192 --batch-size 512 --embedding --log-disable --n-gpu-layers 33 --parallel 4 --port 34587\"\ntime=2024-08-13T17:05:37.542Z level=INFO source=sched.go:445 msg=\"loaded runners\" count=1\ntime=2024-08-13T17:05:37.542Z level=INFO source=server.go:593 msg=\"waiting for llama runner to start responding\"\ntime=2024-08-13T17:05:37.542Z level=INFO source=server.go:627 msg=\"waiting for server to become available\" status=\"llm server error\"\n\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h","output_type":"stream"},{"name":"stdout","text":"INFO [main] build info | build=1 commit=\"1e6f655\" tid=\"134135467356160\" timestamp=1723568737\nINFO [main] system info | n_threads=2 n_threads_batch=-1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"134135467356160\" timestamp=1723568737 total_threads=4\nINFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"6\" port=\"34587\" tid=\"134135467356160\" timestamp=1723568737\n","output_type":"stream"},{"name":"stderr","text":"llama_model_loader: loaded meta data with 29 key-value pairs and 292 tensors from /root/.ollama/models/blobs/sha256-8eeb52dfb3bb9aefdf9d1ef24b3bdbcfbe82238798c4b918278320b6fcef18fe (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.type str              = model\nllama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct\nllama_model_loader: - kv   3:                           general.finetune str              = Instruct\nllama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1\nllama_model_loader: - kv   5:                         general.size_label str              = 8B\nllama_model_loader: - kv   6:                            general.license str              = llama3.1\nllama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\nllama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\nllama_model_loader: - kv   9:                          llama.block_count u32              = 32\nllama_model_loader: - kv  10:                       llama.context_length u32              = 131072\nllama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336\nllama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\nllama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  17:                          general.file_type u32              = 2\nllama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\nllama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\nllama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25hllama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\nllama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25htime=2024-08-13T17:05:37.794Z level=INFO source=server.go:627 msg=\"waiting for server to become available\" status=\"llm server loading model\"\nllama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\nllama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\nllama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\nllama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\nllama_model_loader: - kv  28:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   66 tensors\nllama_model_loader: - type q4_0:  225 tensors\nllama_model_loader: - type q6_K:    1 tensors\n\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25hllm_load_vocab: special tokens cache size = 256\n\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25hllm_load_vocab: token to piece cache size = 0.7999 MB\nllm_load_print_meta: format           = GGUF V3 (latest)\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = BPE\nllm_load_print_meta: n_vocab          = 128256\nllm_load_print_meta: n_merges         = 280147\nllm_load_print_meta: vocab_only       = 0\nllm_load_print_meta: n_ctx_train      = 131072\nllm_load_print_meta: n_embd           = 4096\nllm_load_print_meta: n_layer          = 32\nllm_load_print_meta: n_head           = 32\nllm_load_print_meta: n_head_kv        = 8\nllm_load_print_meta: n_rot            = 128\nllm_load_print_meta: n_swa            = 0\nllm_load_print_meta: n_embd_head_k    = 128\nllm_load_print_meta: n_embd_head_v    = 128\nllm_load_print_meta: n_gqa            = 4\nllm_load_print_meta: n_embd_k_gqa     = 1024\nllm_load_print_meta: n_embd_v_gqa     = 1024\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-05\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: f_logit_scale    = 0.0e+00\nllm_load_print_meta: n_ff             = 14336\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: causal attn      = 1\nllm_load_print_meta: pooling type     = 0\nllm_load_print_meta: rope type        = 0\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 500000.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_ctx_orig_yarn  = 131072\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: ssm_d_conv       = 0\nllm_load_print_meta: ssm_d_inner      = 0\nllm_load_print_meta: ssm_d_state      = 0\nllm_load_print_meta: ssm_dt_rank      = 0\nllm_load_print_meta: model type       = 8B\nllm_load_print_meta: model ftype      = Q4_0\nllm_load_print_meta: model params     = 8.03 B\nllm_load_print_meta: model size       = 4.33 GiB (4.64 BPW) \nllm_load_print_meta: general.name     = Meta Llama 3.1 8B Instruct\nllm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\nllm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\nllm_load_print_meta: LF token         = 128 'Ä'\nllm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\nllm_load_print_meta: max token length = 256\nggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\nggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\nggml_cuda_init: found 1 CUDA devices:\n  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25hllm_load_tensors: ggml ctx size =    0.27 MiB\n\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25hllm_load_tensors: offloading 32 repeating layers to GPU\nllm_load_tensors: offloading non-repeating layers to GPU\nllm_load_tensors: offloaded 33/33 layers to GPU\nllm_load_tensors:        CPU buffer size =   281.81 MiB\nllm_load_tensors:      CUDA0 buffer size =  4156.00 MiB\n\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25hllama_new_context_with_model: n_ctx      = 8192\nllama_new_context_with_model: n_batch    = 512\nllama_new_context_with_model: n_ubatch   = 512\nllama_new_context_with_model: flash_attn = 0\nllama_new_context_with_model: freq_base  = 500000.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:      CUDA0 KV buffer size =  1024.00 MiB\nllama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\nllama_new_context_with_model:  CUDA_Host  output buffer size =     2.02 MiB\nllama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\nllama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\nllama_new_context_with_model: graph nodes  = 1030\nllama_new_context_with_model: graph splits = 2\n\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h","output_type":"stream"},{"name":"stdout","text":"INFO [main] model loaded | tid=\"134135467356160\" timestamp=1723568741\n[GIN] 2024/08/13 - 17:05:41 | 200 |  3.902654251s |       127.0.0.1 | POST     \"/api/generate\"\n","output_type":"stream"},{"name":"stderr","text":"time=2024-08-13T17:05:41.164Z level=INFO source=server.go:632 msg=\"llama runner started in 3.62 seconds\"\n\u001b[?25l\u001b[?25l\u001b[2K\u001b[1G\u001b[?25h\u001b[2K\u001b[1G\u001b[?25h\u001b[?25l\u001b[?25h","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# read x_pred\n\nx_pred = load_json(f\"/kaggle/working/debias_{model}.json\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classificatore di supporto\n\nclassifier_model =  \"llama3.1\"\nshot_classifier_model = 0\n\n#1 = non biased\n#0 = biased\n\ndef num_non_biased(x_pred, classifier_model, shot_classifier_model):\n    start_ollama()\n    pull_model(classifier_model)\n    start_model(classifier_model)\n    time.sleep(500)\n    y_pred = predict(classifier_model,x_pred,shot_classifier_model,False)\n    return y_pred.count(1)\n    \ntotal_debiased = num_non_biased(x_pred,classifier_model,shot_classifier_model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.nltk.org/api/nltk.translate.bleu","metadata":{}},{"cell_type":"code","source":"# calcolo bleu\n\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\nsmoothie = SmoothingFunction().method4 #capisci cos'è smoothing function e method4\nbleu_scores = []\n\n# Itera sulle frasi\nfor test, pred in tqdm(zip(x_test, x_pred)):\n    bleu_score = sentence_bleu([test.split()], pred.split(), smoothing_function=smoothie)\n    bleu_scores.append(bleu_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calcolo rouge\n\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\nrouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n\n# Itera sulle frasi\nfor test, pred in tqdm(zip(x_test, x_pred)):\n    scores = scorer.score(test, pred)\n    rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n    rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n    rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n\n# Calcola la media dei risultati\navg_rouge1 = sum(rouge_scores['rouge1']) / len(rouge_scores['rouge1'])\navg_rouge2 = sum(rouge_scores['rouge2']) / len(rouge_scores['rouge2'])\navg_rougeL = sum(rouge_scores['rougeL']) / len(rouge_scores['rougeL'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calcolo bert_score\n\n# Calcolo del BERTScore per tutte le coppie di frasi\nP, R, F1 = score(x_pred, x_test, lang='en', verbose=True)","metadata":{},"execution_count":null,"outputs":[]}]}