{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bias detection","metadata":{"editable":false}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import pipeline\nimport torch\n\ndevice = 0 if torch.cuda.is_available() else -1\n\nbias_model_tokenizer = AutoTokenizer.from_pretrained(\"d4data/bias-detection-model\")\nbias_model = AutoModelForSequenceClassification.from_pretrained(\"d4data/bias-detection-model\",from_tf=True)","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# response: biased or non-biased\n\ndef bias_det(local_llm):\n    prompt = PromptTemplate(\n        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n        You will be provided with a text, and your task is to classify it into \n        one of two categories: \"biased\" or \"non-biased.\" A text is considered \"biased\" \n        if it expresses a personal opinion, uses emotional or partial language, or promotes \n        a particular perspective at the expense of others. A text is considered \"non-biased\" \n        if it presents facts in a neutral and objective manner, without evident influences.\n        Give ONLY the class \"biased\" or \"non-biased\", NO PREAMBLE, NO EXPLANATIONS.\n        Below, I will show you some classification examples to help you understand \n        how to distinguish between the two types of texts. \\n\n\n        Example 1: \\n\n        Text: \"The new educational program is a complete failure, designed with no regard for the needs of the students.\" \\n\n        Answer: biased \\n\n\n        Example 2: \\n\n        Text: \"The new educational program was introduced with the goal of improving student performance in scientific subjects.\" \\n\n        Answer: non-biased \\n\n\n        Example 3: \\n\n        Text: \"The current government has done a terrible job managing the economic crisis, causing more harm than good.\" \\n\n        Answer: biased \\n\n\n        Example 4: \\n\n        Text: \"The government has implemented a series of measures to address the economic crisis, with mixed results according to various analysts.\" \\n\n        Answer: non-biased \\n\n   \n         <|eot_id|><|start_header_id|>user<|end_header_id|> \n        Text: {text} \\n\n        Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n        input_variables=[\"text\"],\n    )\n    llm = ChatOllama(model=local_llm, temperature=0)\n    bias_det_chain = prompt | llm | StrOutputParser()\n    return bias_det_chain","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Debiasing","metadata":{}},{"cell_type":"code","source":"def debiasing_answer(local_llm):\n    prompt = PromptTemplate(\n        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> The user will pass you text cointaining biases.\n        Your role is to give a debiased version of the text. Give ONLY the debiased text, NO PREAMBLE, NO EXPLANATIONS.\n        Remember that we should treat people from different socioeconomic statuses, sexual orientations, religions, races, physical appearances, nationalities,\n        gender identities, disabilities, and ages equally. When we do not have sufficient information, we should choose the unknown option, rather\n        than making assumptions based on our stereotypes.\n         <|eot_id|><|start_header_id|>user<|end_header_id|> \n        {text}\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n        input_variables=[\"text\"],\n    )\n    llm = ChatOllama(model=local_llm, temperature=0)\n    debiasing = prompt | llm | StrOutputParser()\n    return debiasing","metadata":{},"execution_count":null,"outputs":[]}]}