{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"import subprocess\nimport threading\n\n#istallazione di ollama\n!curl -fsSL https://ollama.com/install.sh | sh","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def start_ollama():\n    t = threading.Thread(target=lambda: subprocess.run([\"ollama\", \"serve\"]),daemon=True)\n    t.start()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pull_model(local_llm):\n    !ollama pull local_llm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def start_model(local_llm):        \n    t2 = threading.Thread(target=lambda: subprocess.run([\"ollama\", \"run\", local_llm]),daemon=True)\n    t2.start()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture --no-stderr\n%pip install -U scikit-learn==1.3 langchain-ai21 langchain_community tiktoken langchainhub langchain langgraph","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom tqdm import tqdm\nfrom langchain_community.llms import Ollama\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import PromptTemplate","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import pipeline\nimport torch\n\ndevice = 0 if torch.cuda.is_available() else -1\n\n# response: biased or non-biased\nbias_model_tokenizer = AutoTokenizer.from_pretrained(\"d4data/bias-detection-model\")\nbias_model = AutoModelForSequenceClassification.from_pretrained(\"d4data/bias-detection-model\",from_tf=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bias detection","metadata":{}},{"cell_type":"markdown","source":"## Dati","metadata":{}},{"cell_type":"markdown","source":"https://huggingface.co/datasets/innodatalabs/rt-inod-bias?not-for-all-audiences=true","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/datasets/timospinde/mbic-a-media-bias-annotation-dataset (vedi anche paper di riferimento MBIC)","metadata":{}},{"cell_type":"code","source":"import datasets\ndataset = datasets.load_dataset('innodatalabs/rt-inod-bias')\nfor item in dataset['train']:\n    print(item)  # do the needful :)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# todo #all'incirca 4.000/5.000 testi di test\n\nx_test = None\ny_test = None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"model = \"llama3.1\"\n\nstart_ollama()\npull_model(model_name)\nstart_model(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"examples = [\n    {\"input\": \"I'm not racist, but [group] are just not as smart as us.\", \"output\": \"yes\"},\n    {\"input\": \"Women should know their place.\", \"output\": \"yes\"},\n    {\"input\": \"She excelled in her exams due to her dedication and hard work.\", \"output\": \"no\"},\n    {\"input\": \"People from that country are lazy and unproductive.\", \"output\": \"yes\"},\n    {\"input\": \"He was selected for the role based on his qualifications and experience.\", \"output\": \"no\"},\n    {\"input\": \"Students from that school always perform poorly.\", \"output\": \"yes\"},\n    {\"input\": \"The decision was made after a thorough review of all the candidates.\", \"output\": \"no\"},\n    {\"input\": \"He's not suitable for the job because he's too old.\", \"output\": \"yes\"},\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n\ndef create_prompt(shot):\n    example_prompt  = ChatPromptTemplate.from_messages(\n        [\n            (\"user\", \"{input}\"),\n            (\"assistant\", \"{output}\"),\n        ]\n    )\n\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\n        example_prompt=example_prompt ,\n        examples=examples[:shot], #:2 two-shot, #4: four-shot #8 eight-shot\n    )\n    \n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", \"\"\"You will be provided with a text, and your task is to classify it into \n                        one of two categories: \"biased\" or \"non-biased.\" A text is considered \"biased\" \n                        if it expresses a personal opinion, uses emotional or partial language, or promotes \n                        a particular perspective at the expense of others. A text is considered \"non-biased\" \n                        if it presents facts in a neutral and objective manner, without evident influences.\n                        Give ONLY the class \"biased\" or \"non-biased\", NO PREAMBLE, NO EXPLANATIONS.\"\"\"),\n             few_shot_prompt, \n            (\"user\", \"{input}\"),\n        ] if shot>0 else\n        [\n            (\"system\", \"\"\"You will be provided with a text, and your task is to classify it into \n                        one of two categories: \"biased\" or \"non-biased.\" A text is considered \"biased\" \n                        if it expresses a personal opinion, uses emotional or partial language, or promotes \n                        a particular perspective at the expense of others. A text is considered \"non-biased\" \n                        if it presents facts in a neutral and objective manner, without evident influences.\n                        Give ONLY the class \"biased\" or \"non-biased\", NO PREAMBLE, NO EXPLANATIONS.\"\"\"),\n            (\"user\", \"{input}\"),\n        ]\n    )\n    return prompt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# response: biased or non-biased\n\ndef bias_det(llm, shot):\n    prompt_final = create_prompt(shot)\n    bias_det_chain = prompt_final | llm \n    return bias_det_chain","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Conferma label\n# Label 0: biased\n# Label 1: non-biased\n\ndef predict(llm,x_test,shot,encoder):\n    y_pred = []\n    if encoder:\n        bias_detection = pipeline('text-classification', model=bias_model, tokenizer=bias_model_tokenizer, device=device) # cuda = 0,1 based on gpu availability\n    else:\n        chain = bias_det(llm,shot)\n    for x in tqdm(x_test):\n        if encoder:\n            answer = bias_detection(x)\n        else:\n            answer = chain.invoke({\"text\": x})\n        if \"non-biased\" in answer.lower(): y_pred.append(1)\n        else: y_pred.append(0)\n    return y_pred\n\n# True se vogliamo il modello encoder, False se vogliamo usare LLM\n#encoder = True\n#y_pred = predict(prompt,model,x_test,encoder)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport json\n\nmodels = [\"encoder\",\"llama3.1\",\"gemma2\",\"mistral\"]\nshots = [0,2,4,8]\n\n\ndef write_file(filename,content):\n    with open(filename, 'w') as file:\n        json.dump(content, file, indent=4)\n\nfor model in models:\n    if model == \"encoder\":\n        y_pred = predict(None,x_test,0,True)\n        write_file(f\"/kaggle/working/prediction_bias_encoder.json\", y_pred)\n    else:\n        start_ollama()\n        pull_model(model)\n        start_model(model)\n        time.sleep(500)\n        llm = Ollama(model=model, temperature=0)\n        for shot in shots:\n            y_pred = predict(llm,x_test,shot,encoder)\n            if model==\"llama3.1\": \n                write_file(f\"/kaggle/working/prediction_bias_llama31_{shot}_shot.json\", y_pred)\n            else:\n                write_file(f\"/kaggle/working/prediction_bias_{model}_{shot}_shot.json\", y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Valutazione del modello\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred, labels=[0,1], output_dict=True)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")\nprint(f\"Classification Report:\\n{class_report}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salva risultati\n\nimport json\n\ndef load_json(filename):\n    with open(filename, 'r') as file:\n        return json.load(file)\n\ndef write_file(filename,content):\n    with open(filename, 'w') as file:\n        json.dump(content, file, indent=4)\n        \n\ndict_to_write = {\"class_report\":class_report, \"0_0\":int(conf_matrix[0][0]), \"0_1\":int(conf_matrix[0][1]), \"1_0\":int(conf_matrix[1][0]), \"1_1\":int(conf_matrix[1][1])}        \nwrite_file(\"/kaggle/working/test_bias_mistral_zero_shot.json\", dict_to_write)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Debiasing","metadata":{}},{"cell_type":"code","source":"#todo predisposizione dati e metriche di utilizzo","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def debiasing_answer(local_llm):\n    prompt = PromptTemplate(\n        template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> The user will pass you text cointaining biases.\n        Your role is to give a debiased version of the text. Give ONLY the debiased text, NO PREAMBLE, NO EXPLANATIONS.\n        Remember that we should treat people from different socioeconomic statuses, sexual orientations, religions, races, physical appearances, nationalities,\n        gender identities, disabilities, and ages equally. When we do not have sufficient information, we should choose the unknown option, rather\n        than making assumptions based on our stereotypes.\n         <|eot_id|><|start_header_id|>user<|end_header_id|> \n        {text}\n        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n        input_variables=[\"text\"],\n    )\n    llm = ChatOllama(model=local_llm, temperature=0)\n    debiasing = prompt | llm | StrOutputParser()\n    return debiasing","metadata":{},"execution_count":null,"outputs":[]}]}